# TELIS Recruitment System

Django-basiertes Rekrutierungssystem fÃ¼r die Verwaltung und Verarbeitung von Leads aus dem LUCA NRW Scraper.

## Quick Start

### 1. Einrichtung der Umgebung

```bash
cd telis_recruitment

# Erstelle eine virtuelle Umgebung
python -m venv venv

# Aktiviere die virtuelle Umgebung
# Unter Linux/Mac:
source venv/bin/activate
# Unter Windows:
# venv\Scripts\activate

# Installiere die AbhÃ¤ngigkeiten
pip install -r requirements.txt
```

### 2. Konfiguration

Erstelle eine `.env` Datei aus der Vorlage:

```bash
cp .env.example .env
```

Bearbeite die `.env` Datei und passe die Werte nach Bedarf an:
- `SECRET_KEY`: Generiere einen sicheren Secret Key fÃ¼r die Produktion
- `DEBUG`: Setze auf `False` fÃ¼r die Produktion
- `ALLOWED_HOSTS`: FÃ¼ge deine Domain(s) hinzu
- `DATABASE_URL`: Konfiguriere deine Datenbank (Standard: SQLite)
- `SCRAPER_PATH`: Pfad zum LUCA Scraper (Standard: `../`)

### 3. Datenbank initialisieren

```bash
# FÃ¼hre Migrationen aus
python manage.py migrate

# Erstelle einen Admin-Benutzer
python manage.py createsuperuser
```

### 4. Development Server starten

```bash
python manage.py runserver
```

Der Server lÃ¤uft jetzt auf http://127.0.0.1:8000/

- Admin-Interface: http://127.0.0.1:8000/admin/
- CRM Dashboard: http://127.0.0.1:8000/crm/
- Scraper Control: http://127.0.0.1:8000/crm/scraper/ (Admin only)
- API-Endpoints: http://127.0.0.1:8000/api/

### 5. Statische Dateien (fÃ¼r Produktion)

```bash
python manage.py collectstatic
```

## Projektstruktur

```
telis_recruitment/
â”œâ”€â”€ manage.py              # Django Management-Skript
â”œâ”€â”€ requirements.txt       # Python-AbhÃ¤ngigkeiten
â”œâ”€â”€ .env.example          # Vorlage fÃ¼r Umgebungsvariablen
â”œâ”€â”€ .env                  # Lokale Umgebungsvariablen (nicht in Git)
â”œâ”€â”€ db.sqlite3            # SQLite-Datenbank (nicht in Git)
â”œâ”€â”€ telis/                # Django-Projektverzeichnis
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py       # Projekteinstellungen
â”‚   â”œâ”€â”€ urls.py           # URL-Konfiguration
â”‚   â”œâ”€â”€ wsgi.py           # WSGI-Konfiguration
â”‚   â””â”€â”€ asgi.py           # ASGI-Konfiguration
â””â”€â”€ leads/                # Lead-Management-App
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ apps.py           # App-Konfiguration
    â”œâ”€â”€ models.py         # Datenmodelle (PR #1b)
    â”œâ”€â”€ admin.py          # Admin-Konfiguration (PR #1c)
    â”œâ”€â”€ views.py          # API-Views (PR #1d)
    â””â”€â”€ urls.py           # App-URLs (PR #1d)
```

## Deployment

FÃ¼r die Produktion mit Gunicorn:

```bash
gunicorn telis.wsgi:application --bind 0.0.0.0:8000
```

## NÃ¤chste Schritte

Nach diesem Setup (PR #1a) folgen:
- **PR #1b**: HinzufÃ¼gen der Datenmodelle (Lead, Company, Contact, etc.)
- **PR #1c**: Admin-Konfiguration fÃ¼r die Verwaltung im Django Admin
- **PR #1d**: REST API-Endpoints fÃ¼r Lead-Management
- **PR #1e**: Import-Command fÃ¼r das Einlesen von Scraper-Daten

## Technologie-Stack

- **Django 4.2**: Web-Framework
- **Django REST Framework**: API-Entwicklung
- **SQLite**: Datenbank (Standard, kann geÃ¤ndert werden)
- **Gunicorn**: WSGI-Server fÃ¼r Produktion
- **Whitenoise**: Statische Dateien
- **CORS Headers**: API-Zugriffskontrolle
- **psutil**: Prozess-Monitoring fÃ¼r Scraper-Control
- **openpyxl**: Excel-Export-FunktionalitÃ¤t

## Features

### ğŸ¯ CRM Dashboard
- Echtzeit-KPIs und Statistiken
- Lead-Verwaltung mit Filterung und Suche
- AktivitÃ¤ts-Feed
- Team-Performance-Ãœbersicht (Manager/Admin)

### ğŸ¤– Scraper-Steuerung (Admin only)
Das integrierte Scraper-Control-Panel ermÃ¶glicht die vollstÃ¤ndige Verwaltung des LUCA Scraper:

- **Start/Stop**: Scraper mit verschiedenen Modi und Parametern starten
- **Live-Monitoring**: Echtzeit-Status, CPU/RAM-Auslastung, Leads-Count
- **Live-Logs**: Server-Sent Events (SSE) fÃ¼r Log-Streaming
- **Historie**: Ãœbersicht Ã¼ber vergangene Scraper-LÃ¤ufe
- **Export**: CSV/Excel-Export mit erweiterten Filtern

**Zugriff:** http://127.0.0.1:8000/crm/scraper/ (erfordert Admin-Berechtigung)

**API-Endpunkte:**
- `POST /crm/api/scraper/start/` - Scraper starten
- `POST /crm/api/scraper/stop/` - Scraper stoppen
- `GET /crm/api/scraper/status/` - Aktueller Status
- `GET /crm/api/scraper/logs/` - Live-Log-Stream (SSE)
- `GET /crm/api/export/csv/` - Lead-Export als CSV
- `GET /crm/api/export/excel/` - Lead-Export als Excel

### ğŸ“Š Export-Funktionen
- CSV-Export mit Filtern
- Excel-Export mit Formatierung
- Filterung nach Status, Quelle, Lead-Typ, Score, Datum
- Automatische Spaltenbreite und Styling

### ğŸ” Berechtigungssystem
- **Admin**: Vollzugriff inkl. Scraper-Control und Einstellungen
- **Manager**: Leads einsehen, Reports, Team-Performance
- **Telefonist**: Nur zugewiesene Leads und Anruf-Funktionen

## Support

Bei Fragen oder Problemen erstelle bitte ein Issue im Repository.
