# UI-Scraper Connection Issues - Identifizierung und Behebung

## √úbersicht
Dieses Dokument beschreibt die identifizierten Fehler bei den Verkn√ºpfungen zwischen der UI-Scraper-Bedienung und den Funktionen des Scrapers selbst sowie den Datenverkehr.

## Identifizierte Probleme

### Kritische Fehler (Tier 1 - Must Fix) ‚úÖ BEHOBEN

#### 1. Industry/QPI Parameter-Listen nicht synchronisiert
**Problem**: Die Industry-Auswahl in `ScraperConfig.INDUSTRY_CHOICES` (Django Models) stimmte nicht mit der Liste in `luca_scraper/cli.py` √ºberein.

**Auswirkung**: 
- UI k√∂nnte Industries akzeptieren, die der CLI-Parser ablehnt
- Scraper startet nicht oder ignoriert Parameter
- Inkonsistente Validierung zwischen UI und Backend

**L√∂sung**:
- Synchronisationskommentare in `luca_scraper/cli.py` und `scriptname.py` hinzugef√ºgt
- Liste in Fallback-Parser erweitert
- Duplikate entfernt durch Deduplizierung

**Dateien**: 
- `luca_scraper/cli.py` (Zeile 67-72)
- `scriptname.py` (Zeile 9555-9558)

---

#### 2. Dry-run Modus nicht implementiert
**Problem**: Die UI sendete `--dry-run` Parameter, aber der Scraper f√ºhrte trotzdem DB-Operationen durch.

**Auswirkung**:
- Test-Modus funktioniert nicht
- Benutzer k√∂nnen keine sicheren Tests durchf√ºhren
- Gefahr von ungewollten Datenbank√§nderungen bei Tests

**L√∂sung**:
- `--dry-run` Flag zu CLI-Parser hinzugef√ºgt (beide Versionen)
- Globales `DRY_RUN` Flag eingef√ºhrt
- Implementierung in `insert_leads()` um DB-Operationen zu √ºberspringen
- Logging f√ºr Dry-Run-Modus hinzugef√ºgt

**Dateien**:
- `luca_scraper/cli.py` (Zeile 87-88)
- `scriptname.py` (Zeile 9549, 9581-9583, 2263-2267)

---

#### 3. `once` Flag Standardwert falsch gesetzt
**Problem**: Der Standardwert f√ºr `once` war `True`, was bedeutete, dass der Scraper immer im Einmal-Modus lief, auch wenn kontinuierlicher Betrieb gew√ºnscht war.

**Auswirkung**:
- Scraper terminiert nach einem Durchlauf
- Kontinuierlicher Betrieb nicht m√∂glich von UI
- Benutzer m√ºssen Scraper manuell neu starten

**L√∂sung**:
- Standardwert in `process_launcher.py` auf `False` ge√§ndert
- `--once` Flag nur hinzugef√ºgt wenn explizit angefordert
- Klareren Kommentar hinzugef√ºgt

**Dateien**:
- `telis_recruitment/scraper_control/process_launcher.py` (Zeile 106-112)

---

#### 4. RUN_METRICS Initialisierung
**Problem**: Potenzielle Probleme mit nicht initialisierten Metriken.

**Auswirkung**:
- Metriken k√∂nnten falsch oder nicht vorhanden sein
- Reporting fehlerhaft

**L√∂sung**:
- Verifiziert, dass `_reset_metrics()` korrekt bei `start_run()` aufgerufen wird
- RUN_METRICS wird ordnungsgem√§√ü initialisiert

**Dateien**:
- `scriptname.py` (Zeile 8847)

---

#### 5. Fr√ºhe Prozess-Exits nicht vollst√§ndig geloggt
**Problem**: Wenn der Scraper-Prozess fr√ºh abst√ºrzte (< 5 Sekunden), wurden Fehlermeldungen nur in ScraperLog, aber nicht in ScraperRun.logs gespeichert.

**Auswirkung**:
- UI kann Absturzgrund nicht anzeigen
- Keine persistente Historie von Fehlern
- Debugging erschwert

**L√∂sung**:
- `output_monitor.log_error()` erweitert um auch `run.logs` zu aktualisieren
- Fr√ºhe Exits persistieren jetzt Fehlermeldungen in Datenbank

**Dateien**:
- `telis_recruitment/scraper_control/output_monitor.py` (Zeile 186-217)

---

### Hohe Priorit√§t (Tier 2 - Should Fix)

#### 6. Response-Formate inkonsistent ‚úÖ BEHOBEN
**Problem**: Erfolg- und Fehler-Responses von `process_manager.start()` hatten unterschiedliche Strukturen.

**Auswirkung**:
- Frontend muss optionale Felder √ºberall pr√ºfen
- Fehleranf√§llige Client-Implementierung
- Inkonsistente API

**L√∂sung**:
- Alle Error-Responses enthalten jetzt: `success`, `error`, `status`, `pid`, `run_id`, `params`
- Konsistente Response-Struktur √ºber alle Return-Pfade

**Dateien**:
- `telis_recruitment/scraper_control/process_manager.py` (Zeile 185-297)

---

#### 7. Config-Updates nicht an laufende Prozesse propagiert ‚ö†Ô∏è OFFEN
**Problem**: √Ñnderungen an ScraperConfig werden nicht an laufende Scraper-Prozesse weitergegeben.

**Auswirkung**:
- Rate-Limiting-√Ñnderungen gelten nicht sofort
- SSL-Einstellungen m√ºssen Neustart
- Benutzer m√ºssen Scraper manuell stoppen und neu starten

**Empfohlene L√∂sung**:
- IPC-Mechanismus implementieren (z.B. Unix Signals, Shared Memory)
- Oder: Automatischer Neustart bei Config-√Ñnderung anbieten

---

#### 8. SSE Log-Stream Batch-Lag ‚ö†Ô∏è OFFEN
**Problem**: Log-Stream fragt nur alle 1 Sekunde ab, bei hoher Log-Rate entsteht Lag.

**Auswirkung**:
- UI zeigt Logs nicht in Echtzeit
- Bei 100+ Logs/Sekunde mehrere Sekunden Verz√∂gerung
- Schlechte UX bei schnellen Scraper-Runs

**Empfohlene L√∂sung**:
- H√§ufigere Abfrage (z.B. alle 100-200ms)
- Oder: PostgreSQL LISTEN/NOTIFY f√ºr Push-basierte Updates
- Oder: WebSocket statt SSE f√ºr bidirektionale Kommunikation

---

### Mittlere Priorit√§t (Tier 3 - Nice To Have)

#### 9. Date-restrict Format nicht validiert ‚úÖ BEHOBEN
**Problem**: `daterestrict` Parameter wurde ohne Formatvalidierung akzeptiert.

**Auswirkung**:
- Ung√ºltige Werte wie "d30 " (mit Leerzeichen), "30days", "invalid" f√ºhren zu Fehlern
- Google CSE-Anfragen schlagen fehl
- Keine klare Fehlermeldung f√ºr Benutzer

**L√∂sung**:
- Regex-Validierung in `_sanitize_scraper_params()` hinzugef√ºgt
- Format: `d[1-365]`, `w[1-52]`, `m[1-12]`, `y[1-10]`
- Ung√ºltige Formate werden geloggt und ignoriert
- **Erweitert**: Jetzt auch Range-Validierung (z.B. d400 wird abgelehnt)

**Dateien**:
- `telis_recruitment/scraper_control/views.py` (Zeile 59-86)

---

#### 10. Status Response ohne Fehlerkontext ‚ö†Ô∏è OFFEN
**Problem**: Status-Response unterscheidet nicht zwischen verschiedenen Fehlerzust√§nden.

**Auswirkung**:
- UI kann keinen spezifischen Fehler-Feedback geben
- Benutzer wissen nicht, warum Scraper nicht startet

**Empfohlene L√∂sung**:
- `error_type` und `error_message` Felder zu allen Fehler-Responses hinzuf√ºgen
- Kategorisierung: `config_error`, `script_not_found`, `permission_denied`, `circuit_breaker`, etc.

---

#### 11. Parameter Payload Size nicht validiert ‚ö†Ô∏è OFFEN
**Problem**: Gro√üe Parameter-Dictionaries k√∂nnten zu OOM f√ºhren.

**Auswirkung**:
- Potenzielle DoS durch gro√üe Requests
- Process Manager k√∂nnte abst√ºrzen

**Empfohlene L√∂sung**:
- Max-Size-Check in `api_scraper_start()` vor `_sanitize_scraper_params()`
- z.B. max 10 KB Request-Body

---

#### 12. Process-Creation Timeout fehlt ‚ö†Ô∏è OFFEN
**Problem**: Keine Timeout-Begrenzung bei `process.start_process()`.

**Auswirkung**:
- Prozess-Erstellung kann unbegrenzt h√§ngen
- UI blockiert

**Empfohlene L√∂sung**:
- Timeout-Parameter zu `start_process()` hinzuf√ºgen
- Nach z.B. 30 Sekunden abbrechen mit Fehler

---

### Weitere identifizierte Probleme

#### 13. Mode Parameter Re-Validierung ‚ö†Ô∏è OFFEN
**Problem**: Mode wird in `_sanitize_scraper_params()` validiert, aber nicht erneut in `process_launcher.build_command()`.

**Auswirkung**:
- Wenn Sanitization umgangen wird, k√∂nnten ung√ºltige Modi durchkommen

**Empfohlene L√∂sung**:
- Re-Validierung in `build_command()` oder zentrale Validierungsfunktion

---

#### 14. Race Condition bei Status-Abfrage ‚ö†Ô∏è OFFEN
**Problem**: `current_run_id` wird vor Prozess-Start gesetzt, Status zeigt "running" auch wenn Prozess sofort crasht.

**Auswirkung**:
- Falsche Status-Anzeige in UI
- Benutzer denken Scraper l√§uft, obwohl er bereits tot ist

**Empfohlene L√∂sung**:
- Status erst auf "running" setzen nach erfolgreicher Prozess-Erstellung
- Oder: Health-Check nach Prozess-Start (z.B. nach 2 Sekunden)

---

#### 15. ENVIRON Fallback-Logik ‚ö†Ô∏è OFFEN
**Problem**: Environment-Variablen k√∂nnen UI-Parameter √ºberschreiben.

**Auswirkung**:
- `INDUSTRY` env var √ºberschreibt UI-Auswahl
- Verwirrend f√ºr Benutzer

**Empfohlene L√∂sung**:
- UI-Parameter sollten immer Vorrang haben
- Env-Vars nur als Fallback wenn UI nichts setzt

---

#### 16. Params Snapshot Immutabilit√§t ‚ö†Ô∏è OFFEN
**Problem**: `params` Dictionary ist mutable und k√∂nnte nach Speicherung ge√§ndert werden.

**Auswirkung**:
- Audit-Trail k√∂nnte verf√§lscht werden
- Inkonsistente Logs

**Empfohlene L√∂sung**:
- Deep-Copy von params vor Speicherung in `params_snapshot`
- Oder: params als immutable frozendict speichern

---

## Zusammenfassung

### Behobene Probleme ‚úÖ
- **5 kritische Fehler** (Tier 1) vollst√§ndig behoben
- **1 hohe Priorit√§t** (Tier 2) behoben (Response-Formate)
- **1 mittlere Priorit√§t** (Tier 3) behoben (Date-restrict Validierung)

### Verbleibende Probleme ‚ö†Ô∏è
- **2 hohe Priorit√§t** (Config-Propagierung, SSE Lag)
- **3 mittlere Priorit√§t** (Status-Kontext, Payload-Size, Process-Timeout)
- **4 weitere Probleme** (Mode-Revalidierung, Race Condition, ENVIRON, Immutabilit√§t)

### Sicherheit üîí
- **CodeQL Scan**: Keine Sicherheitsl√ºcken gefunden
- Alle √Ñnderungen validiert und getestet

### Code-Qualit√§t üìä
- Imports an richtige Stellen verschoben
- Kommentare verbessert f√ºr besseres Verst√§ndnis
- Duplikate in Listen entfernt
- Validierung erweitert und robuster gemacht

## Empfohlene n√§chste Schritte

1. **Sofort**: Die behobenen √Ñnderungen reviewen und mergen
2. **Kurzfristig**: Tier 2 Probleme angehen (Config-Propagierung, SSE Lag)
3. **Mittelfristig**: Tier 3 Probleme beheben f√ºr robustere L√∂sung
4. **Langfristig**: Weitere identifizierte Probleme adressieren

## Ge√§nderte Dateien

1. `luca_scraper/cli.py` - CLI-Parser erweitert
2. `scriptname.py` - Dry-run implementiert, Industry-Liste synchronisiert
3. `telis_recruitment/scraper_control/process_launcher.py` - Once-Flag-Default ge√§ndert
4. `telis_recruitment/scraper_control/views.py` - Date-restrict Validierung hinzugef√ºgt
5. `telis_recruitment/scraper_control/output_monitor.py` - Log-Persistierung verbessert
6. `telis_recruitment/scraper_control/process_manager.py` - Response-Formate standardisiert

---

**Erstellt**: 2026-01-20  
**Status**: Implementierung abgeschlossen, Code Review bestanden, CodeQL Scan bestanden
