# ğŸ†˜ Troubleshooting Guide

Dieser Guide hilft dir, hÃ¤ufige Probleme **nach Symptomen** zu lÃ¶sen - nicht nach Technik. Finde dein Problem und folge der LÃ¶sung.

---

## ğŸ” Schnell-Navigation

| Symptom | Kategorie |
|---------|-----------|
| [Ich bekomme 0 Leads](#ich-bekomme-0-leads) | ğŸ¯ Leads & Daten |
| [Zu wenige Leads (< 10)](#zu-wenige-leads-10) | ğŸ¯ Leads & Daten |
| [Login/Session klappt nicht](#loginsession-klappt-nicht) | ğŸ” Authentifizierung |
| [Zu viele 403/Blockaden](#zu-viele-403blockaden) | ğŸš« Rate Limits |
| [CRM zeigt nichts an](#crm-zeigt-nichts-an) | ğŸ’» CRM/UI |
| [Scraper lÃ¤uft, aber speichert nicht](#scraper-lÃ¤uft-aber-speichert-nicht) | ğŸ’¾ Datenbank |
| [Port already in use](#port-already-in-use) | ğŸ”Œ Server |
| [Static Files not loading](#static-files-not-loading) | ğŸ¨ Frontend |
| [Docker Container fails](#docker-container-fails) | ğŸ³ Docker |
| [API-Kosten explodieren](#api-kosten-explodieren) | ğŸ’° Kosten |

---

## ğŸ¯ Leads & Daten

### Ich bekomme 0 Leads

**Symptome:**
- Scraper lÃ¤uft durch ohne Fehler
- Dashboard zeigt 0 Leads
- Keine EintrÃ¤ge in der Datenbank

#### Ursache 1: Keine Suchergebnisse gefunden

**Check:**
```bash
# Schaue in die Logs
docker-compose logs -f web  # Docker
# oder schaue im Terminal wo der Scraper lÃ¤uft

# Suche nach:
# "No results found" oder "0 URLs fetched"
```

**LÃ¶sung:**
```bash
# 1. Date Restrict erweitern (mehr Zeitraum)
python scriptname.py --once --industry recruiter --qpi 6 --daterestrict d90

# 2. Andere Industry testen
python scriptname.py --once --industry talent_hunt --qpi 8

# 3. QPI erhÃ¶hen (mehr Queries)
python scriptname.py --once --industry recruiter --qpi 12
```

#### Ursache 2: Alle Leads werden gefiltert

**Check:**
```bash
# Schaue nach Rejection Stats
python scriptname.py --show-stats

# Oder in den Logs nach:
# "Rejected: invalid_name" oder "Rejected: no_contact"
```

**LÃ¶sung:**
```bash
# Option 1: Validierung temporÃ¤r lockern (fÃ¼r Test)
# Edit scriptname.py oder in der .env:
LEAD_VALIDATION_STRICT=False

# Option 2: Minimum Score senken
python scriptname.py --once --industry recruiter --qpi 12 --min-score 50
```

#### Ursache 3: Datenbank-Pfad falsch

**Check:**
```bash
# PrÃ¼fe ob Datenbank existiert
ls -la telis_recruitment/db.sqlite3

# PrÃ¼fe Permissions
ls -la telis_recruitment/db.sqlite3
# Sollte schreibbar sein
```

**LÃ¶sung:**
```bash
# Datenbank neu initialisieren
cd telis_recruitment
python manage.py migrate

# Oder fÃ¼r Docker:
docker-compose exec web python manage.py migrate
```

#### Ursache 4: Blocked by Websites

**Check:**
```bash
# In Logs nach 403, 429, 503 Errors suchen
# "HTTP 403" oder "blocked" oder "rate limit"
```

**LÃ¶sung:**
- Siehe [Zu viele 403/Blockaden](#zu-viele-403blockaden)

---

### Zu wenige Leads (< 10)

**Symptome:**
- Scraper lÃ¤uft erfolgreich
- Nur 1-5 Leads werden gespeichert
- Erwartet wurden 10-30+ Leads

#### LÃ¶sung 1: QPI erhÃ¶hen

```bash
# Von Safe Mode (6) zu Balanced Mode (12)
python scriptname.py --once --industry recruiter --qpi 12 --daterestrict d60
```

#### LÃ¶sung 2: Date Restrict erweitern

```bash
# Mehr Zeitraum = mehr potenzielle Ergebnisse
python scriptname.py --once --industry recruiter --qpi 12 --daterestrict d90
```

#### LÃ¶sung 3: Mehrere Industries kombinieren

```bash
# Parallel mehrere Industries scrapen
python scriptname.py --once --industry recruiter --qpi 10 &
python scriptname.py --once --industry talent_hunt --qpi 8 &
wait
```

#### LÃ¶sung 4: Google Custom Search API nutzen

**Vorteil:** Mehr Queries mÃ¶glich (100 Queries/Tag gratis)

```bash
# 1. API Key holen
# Gehe zu: https://developers.google.com/custom-search/v1/introduction
# Erstelle API Key und Custom Search Engine ID

# 2. In .env eintragen
GOOGLE_API_KEY=your-key-here
GOOGLE_CSE_ID=your-cse-id-here

# 3. Scraper nutzt automatisch Google CSE wenn verfÃ¼gbar
python scriptname.py --once --industry recruiter --qpi 20
```

---

## ğŸ” Authentifizierung

### Login/Session klappt nicht

**Symptome:**
- "Invalid credentials" beim Login
- Nach Login sofort wieder auf Login-Seite
- Session expired Meldungen

#### Ursache 1: Falscher Admin User

**LÃ¶sung:**
```bash
# Docker
docker-compose exec web python manage.py createsuperuser

# Manuell
cd telis_recruitment
python manage.py createsuperuser

# Folge den Prompts und erstelle neuen User
```

#### Ursache 2: SECRET_KEY fehlt oder falsch

**Check:**
```bash
# PrÃ¼fe .env Datei
cat .env | grep SECRET_KEY

# Sollte NICHT leer sein und nicht "change-me" enthalten
```

**LÃ¶sung:**
```bash
# Neuen SECRET_KEY generieren
python -c "from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())"

# Output kopieren und in .env eintragen:
SECRET_KEY=dein-neuer-generierter-key-hier

# Server neu starten
docker-compose restart web  # Docker
# oder Ctrl+C und python manage.py runserver fÃ¼r manuell
```

#### Ursache 3: CSRF Token Probleme

**Check:**
```bash
# In Browser Console (F12) nach CSRF errors suchen
```

**LÃ¶sung:**
```bash
# In .env: CSRF_TRUSTED_ORIGINS setzen
CSRF_TRUSTED_ORIGINS=http://localhost:8000,http://127.0.0.1:8000

# FÃ¼r Produktion mit Domain:
CSRF_TRUSTED_ORIGINS=https://yourdomain.com,https://www.yourdomain.com

# Server neu starten
```

#### Ursache 4: Browser Cache

**LÃ¶sung:**
```
1. Ã–ffne Browser Dev Tools (F12)
2. Rechtsklick auf Reload Button
3. WÃ¤hle "Empty Cache and Hard Reload"
4. Oder: Private/Incognito Fenster verwenden
```

---

## ğŸš« Rate Limits & Blockaden

### Zu viele 403/Blockaden

**Symptome:**
- Viele "HTTP 403 Forbidden" in Logs
- "Access Denied" oder "blocked" Meldungen
- Scraper stoppt vorzeitig
- < 20% Success Rate

#### Ursache 1: Zu viele Requests zu schnell

**LÃ¶sung 1: QPI reduzieren**
```bash
# Von Aggressive (20) zu Balanced (12)
python scriptname.py --once --industry recruiter --qpi 12 --daterestrict d60
```

**LÃ¶sung 2: Delay erhÃ¶hen**

Edit `scriptname.py` (temporÃ¤r fÃ¼r Test):
```python
# Suche nach: DELAY_BETWEEN_REQUESTS
# Ã„ndere von 1-2 zu 3-5 Sekunden
DELAY_BETWEEN_REQUESTS = 3  # oder 5
```

**LÃ¶sung 3: Nur zu Off-Peak Zeiten scrapen**
```bash
# Nachts oder frÃ¼h morgens (weniger Competition)
# z.B. Cron Job um 4 Uhr morgens
0 4 * * * cd /path/to/luca && python scriptname.py --once --qpi 12
```

#### Ursache 2: IP-Adresse geblockt

**LÃ¶sung 1: Proxy verwenden**

```bash
# In .env:
HTTP_PROXY=http://your-proxy:port
HTTPS_PROXY=https://your-proxy:port

# Oder Command-Line:
export HTTP_PROXY=http://your-proxy:port
python scriptname.py --once --industry recruiter --qpi 12
```

**LÃ¶sung 2: VPN nutzen**
- Aktiviere VPN
- Wechsle Server-Standort
- FÃ¼hre Scraper erneut aus

**LÃ¶sung 3: IP rotieren lassen**
- Warte 24 Stunden
- Oder: Nutze dynamische IP (Router neu starten)

#### Ursache 3: User-Agent geblockt

Der Scraper rotiert User-Agents automatisch, aber falls Problem besteht:

```python
# Check in scriptname.py:
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64)...",
    # Sind mehrere definiert?
]
```

---

## ğŸ’» CRM & UI

### CRM zeigt nichts an

**Symptome:**
- Dashboard lÃ¤dt, aber zeigt 0 Leads
- Leads sollten vorhanden sein
- Oder: Dashboard lÃ¤dt gar nicht

#### Ursache 1: Keine Leads in Datenbank

**Check:**
```bash
# Docker
docker-compose exec web python manage.py shell
>>> from crm.models import Lead
>>> Lead.objects.count()
# Sollte > 0 sein wenn Leads vorhanden

# Manuell
cd telis_recruitment
python manage.py shell
>>> from crm.models import Lead
>>> Lead.objects.count()
```

**LÃ¶sung:**
- Wenn 0: Siehe [Ich bekomme 0 Leads](#ich-bekomme-0-leads)
- Wenn > 0: Ursache 2 oder 3

#### Ursache 2: Falsche Datenbank wird gelesen

**Check:**
```bash
# PrÃ¼fe DATABASE_URL in .env
cat .env | grep DATABASE_URL

# Sollte sein:
DATABASE_URL=sqlite:///db.sqlite3
```

**LÃ¶sung:**
```bash
# Falls falsch, korrigiere in .env:
DATABASE_URL=sqlite:///db.sqlite3

# Server neu starten
docker-compose restart web  # Docker
# oder Ctrl+C und python manage.py runserver
```

#### Ursache 3: Static Files nicht geladen

**Symptome:**
- Dashboard lÃ¤dt, aber ohne Styling
- Nur Text sichtbar, kein Design

**LÃ¶sung:**
```bash
# Docker
docker-compose exec web python manage.py collectstatic --noinput

# Manuell
cd telis_recruitment
python manage.py collectstatic --noinput

# Server neu starten
```

#### Ursache 4: JavaScript Fehler

**Check:**
```
1. Ã–ffne Browser Dev Tools (F12)
2. Gehe zum "Console" Tab
3. Suche nach roten Fehlermeldungen
```

**HÃ¤ufige Fehler & LÃ¶sungen:**

**Fehler:** "Failed to load resource: 404"
```bash
# Static files fehlen
python manage.py collectstatic --noinput
```

**Fehler:** "CSRF token missing"
```bash
# Siehe: Login/Session klappt nicht
```

---

## ğŸ’¾ Datenbank

### Scraper lÃ¤uft, aber speichert nicht

**Symptome:**
- Scraper zeigt "Processing..." und "Found leads"
- Aber: Datenbank bleibt leer
- Keine Fehler sichtbar

#### Ursache 1: Datenbank-Permissions

**Check:**
```bash
# PrÃ¼fe ob db.sqlite3 existiert und schreibbar ist
ls -la telis_recruitment/db.sqlite3

# Sollte nicht read-only sein
# Sollte dem User gehÃ¶ren, der den Server startet
```

**LÃ¶sung:**
```bash
# Permissions korrigieren
chmod 644 telis_recruitment/db.sqlite3
chown $USER:$USER telis_recruitment/db.sqlite3

# FÃ¼r Docker: Container user muss schreiben kÃ¶nnen
docker-compose exec web chown -R app:app /app/telis_recruitment/db.sqlite3
```

#### Ursache 2: Falscher Datenbank-Pfad

**Check:**
```bash
# Im Scraper: PrÃ¼fe Database Path
grep "DB_PATH" scriptname.py

# Sollte auf telis_recruitment/db.sqlite3 zeigen
```

**LÃ¶sung:**

Edit `scriptname.py` (falls nÃ¶tig):
```python
# Suche nach DB_PATH Definition
DB_PATH = "telis_recruitment/db.sqlite3"  # Korrekter Pfad
```

#### Ursache 3: Transactions nicht committed

**Check:**
```bash
# In Logs nach "rollback" oder "transaction error" suchen
```

**LÃ¶sung:**
```bash
# Datenbank neu initialisieren (ACHTUNG: LÃ¶scht Daten!)
rm telis_recruitment/db.sqlite3
cd telis_recruitment
python manage.py migrate
```

#### Ursache 4: Duplikate werden ignoriert

**Das ist eigentlich gewÃ¼nschtes Verhalten!**

Der Scraper ignoriert Duplikate basierend auf:
- E-Mail
- Telefonnummer
- URL

**Check ob es wirklich neue Leads sind:**
```bash
# Im CRM: Suche nach E-Mail oder Telefon
# Oder in DB:
cd telis_recruitment
python manage.py shell
>>> from crm.models import Lead
>>> Lead.objects.filter(email="test@example.com").exists()
```

---

## ğŸ”Œ Server & Installation

### Port already in use

**Symptome:**
- `Error: That port is already in use.`
- Server startet nicht

**LÃ¶sung 1: Port 8000 freigeben**

```bash
# Linux/Mac: Process finden und killen
lsof -ti:8000 | xargs kill -9

# Windows: Process finden
netstat -ano | findstr :8000
# Dann killen mit PID:
taskkill /PID <PID> /F
```

**LÃ¶sung 2: Anderen Port verwenden**

```bash
# Docker: Edit docker-compose.yml
ports:
  - "8080:8000"  # Statt 8000:8000

# Manuell
python manage.py runserver 0.0.0.0:8080
```

### Static Files not loading

**Symptome:**
- CSS/JS Files nicht gefunden
- Seite sieht "kaputt" aus
- 404 Fehler fÃ¼r /static/...

**LÃ¶sung:**
```bash
# Docker
docker-compose exec web python manage.py collectstatic --noinput --clear

# Manuell
cd telis_recruitment
python manage.py collectstatic --noinput --clear

# PrÃ¼fe STATIC_ROOT in .env:
STATIC_ROOT=staticfiles

# Server neu starten
```

---

## ğŸ³ Docker

### Docker Container fails

**Symptome:**
- `docker-compose up` startet, aber Container stoppt sofort
- Exit code > 0

**Check Logs:**
```bash
docker-compose logs web
# Oder fÃ¼r alle Services:
docker-compose logs
```

**HÃ¤ufige Ursachen & LÃ¶sungen:**

#### Ursache 1: .env fehlt oder SECRET_KEY fehlt

```bash
# Check ob .env existiert
ls -la .env

# Falls nicht:
cp .env.example .env
nano .env
# SECRET_KEY setzen (siehe oben)

# Container neu starten
docker-compose up -d
```

#### Ursache 2: Dependencies nicht installiert

```bash
# Rebuild mit --no-cache
docker-compose up -d --build --no-cache
```

#### Ursache 3: Port Conflict

```bash
# PrÃ¼fe ob Port 8000 belegt ist
lsof -ti:8000  # Linux/Mac
netstat -ano | findstr :8000  # Windows

# Falls ja: Siehe "Port already in use"
```

#### Ursache 4: Volume Permissions

```bash
# Remove volumes und neu starten
docker-compose down -v
docker-compose up -d

# Oder: Permissions im Container fixen
docker-compose exec web chown -R app:app /app
```

---

## ğŸ’° Kosten

### API-Kosten explodieren

**Symptome:**
- OpenAI/Perplexity Kosten unerwartet hoch
- Mehr als â‚¬1 pro Tag
- Viele API Calls in Logs

#### LÃ¶sung 1: AI-Enrichment temporÃ¤r deaktivieren

```bash
# In .env: API Keys leer lassen
OPENAI_API_KEY=
PERPLEXITY_API_KEY=

# Scraper funktioniert weiterhin (ohne AI-Features)
# Server neu starten
```

#### LÃ¶sung 2: QPI reduzieren

```bash
# Weniger Queries = weniger Leads = weniger API Calls
python scriptname.py --once --industry recruiter --qpi 6 --daterestrict d30
```

#### LÃ¶sung 3: Weniger hÃ¤ufige Runs

```bash
# Statt tÃ¤glich: nur 2-3x pro Woche
# Oder: nur bei Bedarf manuell triggern
```

#### LÃ¶sung 4: Budget Limits setzen

```
1. Gehe zu OpenAI Dashboard: https://platform.openai.com/account/limits
2. Setze "Hard limit" z.B. auf $10/month
3. Setze "Soft limit" z.B. auf $5/month (Email-Warnung)
```

#### LÃ¶sung 5: GÃ¼nstigeres Modell verwenden

Falls du AI-Config anpassen kannst:
```python
# Statt GPT-4:
model = "gpt-3.5-turbo"  # Deutlich gÃ¼nstiger

# Oder:
model = "gpt-4o-mini"  # Neues gÃ¼nstiges Modell
```

---

## ğŸ”§ Erweiterte Diagnose

### Debug-Modus aktivieren

FÃ¼r detaillierte Logs:

```bash
# In .env:
DEBUG=True
LOG_LEVEL=DEBUG

# Server neu starten
# ACHTUNG: Nur fÃ¼r Development! In Production: DEBUG=False
```

### Datenbank-Inspektion

```bash
# Shell Ã¶ffnen
cd telis_recruitment
python manage.py shell

# Leads anzeigen
>>> from crm.models import Lead
>>> leads = Lead.objects.all()
>>> for lead in leads[:5]:
...     print(f"{lead.name} - {lead.email} - Score: {lead.score}")

# Scraper Stats
>>> Lead.objects.count()
>>> Lead.objects.filter(score__gte=80).count()
```

### Scraper Test-Run

Minimaler Test ohne CRM:

```bash
# Standalone Test
python -c "
import sqlite3
con = sqlite3.connect('telis_recruitment/db.sqlite3')
cur = con.cursor()
cur.execute('SELECT COUNT(*) FROM crm_lead')
print(f'Total Leads: {cur.fetchone()[0]}')
con.close()
"
```

---

## ğŸ“š WeiterfÃ¼hrende Hilfe

Wenn dein Problem hier nicht gelÃ¶st wurde:

1. **GitHub Issues durchsuchen:**
   - https://github.com/sundsoffice-tech/luca-nrw-scraper/issues
   - Vielleicht hatte jemand das gleiche Problem

2. **Neues Issue erstellen:**
   - Beschreibe das Problem
   - Inkludiere: Logs, OS, Installation-Methode
   - Inkludiere: Was du bereits versucht hast

3. **Dokumentation lesen:**
   - [Installation Guide](INSTALLATION.md)
   - [Deployment Guide](DEPLOYMENT.md)
   - [Configuration Profiles](CONFIGURATION_PROFILES.md)

4. **Community fragen:**
   - GitHub Discussions
   - Stack Overflow (Tag: luca-nrw-scraper)

---

## ğŸ¯ Checkliste: Gesundes System

Nutze diese Checkliste um sicherzustellen, dass alles funktioniert:

```
âœ… Server startet ohne Fehler
âœ… CRM Dashboard lÃ¤dt korrekt
âœ… Login funktioniert
âœ… Scraper lÃ¤uft und findet Leads (> 10)
âœ… Leads werden in DB gespeichert
âœ… CRM zeigt Leads an
âœ… Export funktioniert (CSV/Excel)
âœ… < 10% Error Rate beim Scrapen
âœ… API-Kosten im Budget
âœ… Logs zeigen keine kritischen Fehler
```

Wenn alle Punkte âœ… sind: System ist healthy! ğŸ‰

---

**Noch Fragen?** [GitHub Issues](https://github.com/sundsoffice-tech/luca-nrw-scraper/issues) | [README.md](../README.md)
