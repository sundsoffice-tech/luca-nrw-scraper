# Human-in-the-Loop Login System

## √úbersicht

Das Login-System erm√∂glicht es dem Scraper, automatisch zu erkennen, wenn ein Portal einen Login erfordert, und den Benutzer aufzufordern, sich manuell einzuloggen. Die Session-Cookies werden dann gespeichert und f√ºr zuk√ºnftige Anfragen wiederverwendet.

## Features

- ‚úÖ **Automatische Login-Erkennung**: Erkennt Login-Anforderungen anhand von Status-Codes (403, 401, 429), Text-Patterns und URL-Patterns
- ‚úÖ **Browser-basierter Login**: √ñffnet Browser f√ºr manuellen Login (Selenium oder Standard-Browser)
- ‚úÖ **Session-Speicherung**: Speichert Cookies in SQLite-Datenbank mit 7-Tage-Ablauf
- ‚úÖ **Session-Wiederverwendung**: Verwendet gespeicherte Cookies automatisch
- ‚úÖ **Portal-spezifisch**: Unterst√ºtzt verschiedene Portale (LinkedIn, XING, Indeed, Kleinanzeigen, etc.)
- ‚úÖ **Dashboard-Integration**: Zeigt aktive/abgelaufene Sessions im Dashboard an
- ‚úÖ **CLI-Verwaltung**: Kommandozeilen-Tools zum Verwalten von Sessions

## Unterst√ºtzte Portale

- **kleinanzeigen.de** - Kleinanzeigen Stellengesuche
- **linkedin.com** - LinkedIn Profile
- **xing.com** - XING Profile
- **indeed.com/indeed.de** - Indeed Jobs
- **facebook.com** - Facebook
- **stepstone.de** - Stepstone Jobs
- **monster.de** - Monster Jobs
- **quoka.de** - Quoka
- **markt.de** - Markt.de

## Installation

Selenium ist optional, aber empfohlen f√ºr bessere Cookie-Extraktion:

```bash
pip install selenium>=4.0.0
```

## Verwendung

### 1. Automatische Login-Erkennung w√§hrend des Scrapings

Der Scraper erkennt automatisch, wenn ein Login erforderlich ist:

```bash
python scriptname.py --once --industry candidates
```

Wenn ein Login erforderlich ist, erscheint:

```
============================================================
üîê LOGIN ERFORDERLICH
============================================================
Portal: LINKEDIN
URL: https://www.linkedin.com/login
------------------------------------------------------------
üåê √ñffne Chrome Browser...
üëâ Bitte logge dich ein und dr√ºcke ENTER wenn fertig.
------------------------------------------------------------

‚è≥ Dr√ºcke ENTER wenn du eingeloggt bist...
```

### 2. Manuelles Einloggen vor dem Scraping

Logge dich manuell bei einem Portal ein:

```bash
# LinkedIn
python scriptname.py --login linkedin

# XING
python scriptname.py --login xing

# Kleinanzeigen
python scriptname.py --login kleinanzeigen
```

### 3. Sessions anzeigen

Zeige alle gespeicherten Sessions:

```bash
python scriptname.py --list-sessions
```

Ausgabe:
```
‚úÖ linkedin: 2025-12-23 14:30:00
‚úÖ xing: 2025-12-23 15:45:00
‚ùå facebook: 2025-12-20 10:00:00  (abgelaufen)
```

### 4. Sessions l√∂schen

L√∂sche alle gespeicherten Sessions:

```bash
python scriptname.py --clear-sessions
```

### 5. Dashboard anzeigen

Das Dashboard zeigt den Status aller Login-Sessions:

```bash
python dashboard.py
```

Ausgabe:
```
üîê LOGIN SESSIONS
-----------------------------------------------------------------
  ‚úÖ linkedin            Login: 2025-12-23  Expires: 2025-12-30
  ‚úÖ xing                Login: 2025-12-23  Expires: 2025-12-30
  ‚ùå facebook            Login: 2025-12-20  Expires: 2025-12-27
```

## Wie es funktioniert

### Login-Erkennung

Das System erkennt Login-Anforderungen durch:

1. **Status-Codes**: 401 (Unauthorized), 403 (Forbidden), 429 (Too Many Requests)
2. **Text-Patterns** (case-insensitive):
   - "bitte anmelden", "bitte einloggen"
   - "login required", "please log in"
   - "captcha", "sind sie ein roboter"
   - "access denied", "zugang verweigert"
   - "unusual traffic", "too many requests"
3. **URL-Patterns**: URLs die "login", "signin", "anmelden", "einloggen" enthalten

### Session-Speicherung

Sessions werden in zwei Orten gespeichert:

1. **SQLite-Datenbank** (`scraper.db`, Tabelle `login_sessions`):
   - Portal-Name
   - Cookies (JSON)
   - User-Agent
   - Login-Zeitstempel
   - Ablaufdatum (7 Tage)
   - G√ºltigkeitsflag

2. **JSON-Backup-Dateien** (`sessions/` Verzeichnis):
   - `{portal}_cookies.json` f√ºr jedes Portal
   - Enth√§lt Cookies, User-Agent und Zeitstempel

### Browser-Integration

**Mit Selenium** (empfohlen):
- √ñffnet Chrome mit speziellen Optionen
- Benutzer loggt sich manuell ein
- Cookies werden automatisch extrahiert
- Browser wird geschlossen

**Ohne Selenium** (Fallback):
- √ñffnet Standard-Browser
- Benutzer loggt sich manuell ein
- Optional: Cookies k√∂nnen manuell eingef√ºgt werden (JSON-Format)
- Session wird als "versucht" markiert

## Programmatische Verwendung

### In eigenem Code verwenden

```python
from login_handler import LoginHandler, get_login_handler, check_and_handle_login

# Login-Handler initialisieren
handler = get_login_handler()

# Login-Anforderung pr√ºfen
response_text = "..."
status_code = 403
url = "https://www.linkedin.com/in/profile"

if handler.detect_login_required(response_text, status_code, url):
    portal = handler.get_portal_from_url(url)
    
    # Pr√ºfe ob g√ºltige Session existiert
    if handler.has_valid_session(portal):
        cookies = handler.get_session_cookies(portal)
        # Verwende Cookies f√ºr Request
    else:
        # Fordere manuellen Login an
        cookies = handler.request_manual_login(portal, url)
```

### Mit fetch_with_login_check

Der Scraper enth√§lt eine Helper-Funktion:

```python
# In scriptname.py
response = await fetch_with_login_check(url, headers=headers)
```

Diese Funktion:
1. L√§dt gespeicherte Cookies falls vorhanden
2. F√ºhrt Request aus
3. Pr√ºft Response auf Login-Anforderungen
4. Loggt Warnung wenn Login erforderlich ist

## Sicherheit

- ‚úÖ **Sensitive Daten gesch√ºtzt**: `sessions/` Verzeichnis ist in `.gitignore`
- ‚úÖ **Lokale Speicherung**: Cookies werden nur lokal gespeichert
- ‚úÖ **Keine Third-Party**: Keine Daten werden an Dritte gesendet
- ‚úÖ **Automatische Ablaufdaten**: Sessions laufen nach 7 Tagen ab
- ‚úÖ **CodeQL gepr√ºft**: Keine Sicherheitsl√ºcken gefunden

## Troubleshooting

### Selenium funktioniert nicht

**Problem**: "Selenium-Fehler: ..."

**L√∂sung**:
1. Installiere Selenium: `pip install selenium>=4.0.0`
2. Installiere ChromeDriver (wird automatisch von Selenium verwaltet)
3. Falls weiterhin Probleme: System verwendet automatisch Fallback auf Standard-Browser

### Cookies werden nicht gespeichert

**Problem**: "‚ùå Keine Cookies gefunden"

**L√∂sung**:
1. Stelle sicher, dass du dich erfolgreich eingeloggt hast
2. Warte bis die Seite vollst√§ndig geladen ist
3. Dr√ºcke erst dann ENTER
4. Bei Fallback-Browser: Kopiere Cookies manuell aus DevTools

### Session abgelaufen

**Problem**: "Login erforderlich" trotz gespeicherter Session

**L√∂sung**:
1. Sessions laufen nach 7 Tagen ab
2. Portal k√∂nnte Session serverseitig ung√ºltig gemacht haben
3. F√ºhre neuen Login durch: `python scriptname.py --login {portal}`

### Portal wird nicht erkannt

**Problem**: "Portal: UNKNOWN"

**L√∂sung**:
1. Portal ist noch nicht in der Liste
2. F√ºge Portal zu `PORTAL_LOGIN_URLS` in `login_handler.py` hinzu
3. F√ºge Domain zu `portal_domains` in `get_portal_from_url()` hinzu

## Erweiterung

### Neues Portal hinzuf√ºgen

In `login_handler.py`:

```python
# Portal-spezifische Login-URLs
PORTAL_LOGIN_URLS = {
    # ... existing portals ...
    "neuportal": "https://www.neuportal.de/login",
}

# In get_portal_from_url()
portal_domains = {
    # ... existing domains ...
    "neuportal.de": "neuportal",
}
```

### Neue Login-Patterns hinzuf√ºgen

In `login_handler.py`:

```python
LOGIN_INDICATORS = [
    # ... existing patterns ...
    "neues pattern hier",
    "another pattern",
]
```

## API-Referenz

### LoginHandler

**Konstruktor**:
```python
handler = LoginHandler(db_path="scraper.db")
```

**Methoden**:
- `detect_login_required(response_text, status_code, url)` - Erkennt Login-Anforderung
- `get_portal_from_url(url)` - Ermittelt Portal-Name aus URL
- `has_valid_session(portal)` - Pr√ºft ob g√ºltige Session existiert
- `get_session_cookies(portal)` - L√§dt gespeicherte Cookies
- `save_session(portal, cookies, user_agent)` - Speichert Session
- `invalidate_session(portal)` - Markiert Session als ung√ºltig
- `request_manual_login(portal, url)` - Fordert manuellen Login an
- `get_all_sessions()` - Gibt alle Sessions zur√ºck

### Globale Funktionen

- `get_login_handler()` - Gibt Singleton-Instanz zur√ºck
- `check_and_handle_login(response_text, status_code, url)` - Pr√ºft und handelt Login

## Beispiele

### Beispiel 1: Alle LinkedIn-Profile einer Liste scrapen

```bash
# 1. Login bei LinkedIn
python scriptname.py --login linkedin

# 2. Scraper starten
python scriptname.py --once --industry candidates
```

### Beispiel 2: Sessions vor gro√üem Scraping-Lauf vorbereiten

```bash
# Login bei allen relevanten Portalen
python scriptname.py --login linkedin
python scriptname.py --login xing
python scriptname.py --login kleinanzeigen

# Sessions anzeigen
python scriptname.py --list-sessions

# Scraping starten
python scriptname.py --once --industry all
```

### Beispiel 3: Sessions nach Scraping-Problemen zur√ºcksetzen

```bash
# Alte Sessions l√∂schen
python scriptname.py --clear-sessions

# Neu einloggen
python scriptname.py --login linkedin

# Erneut versuchen
python scriptname.py --once --industry candidates
```

## Lizenz

Teil des luca-nrw-scraper Projekts.
